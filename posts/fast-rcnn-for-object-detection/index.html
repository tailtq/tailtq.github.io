<!DOCTYPE html><html lang="en-US" mode="light" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="generator" content="Jekyll v4.3.2" /><meta property="og:title" content="Fast R-CNN cho nhận diện đối tượng" /><meta name="author" content="Tai Le" /><meta property="og:locale" content="en_US" /><meta name="description" content="Sau khi đã tìm hiểu về R-CNN, chúng ta hãy cùng đi tìm hiểu về một kiến trúc tối tân hơn R-CNN vào năm 2015, chỉ 1 năm sau sự ra đời của nó, đó chính là Fast R-CNN. Fast R-CNN là một phiên bản hoàn thiện hơn và khắc phục được các hạn chế mà R-CNN còn mắc phải." /><meta property="og:description" content="Sau khi đã tìm hiểu về R-CNN, chúng ta hãy cùng đi tìm hiểu về một kiến trúc tối tân hơn R-CNN vào năm 2015, chỉ 1 năm sau sự ra đời của nó, đó chính là Fast R-CNN. Fast R-CNN là một phiên bản hoàn thiện hơn và khắc phục được các hạn chế mà R-CNN còn mắc phải." /><link rel="canonical" href="https://tailtq.github.io/posts/fast-rcnn-for-object-detection/" /><meta property="og:url" content="https://tailtq.github.io/posts/fast-rcnn-for-object-detection/" /><meta property="og:site_name" content="Tailtq" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2020-09-14T00:00:00+07:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Fast R-CNN cho nhận diện đối tượng" /><meta name="twitter:site" content="@twitter_username" /><meta name="twitter:creator" content="@Tai Le" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Tai Le"},"dateModified":"2022-08-07T23:49:43+07:00","datePublished":"2020-09-14T00:00:00+07:00","description":"Sau khi đã tìm hiểu về R-CNN, chúng ta hãy cùng đi tìm hiểu về một kiến trúc tối tân hơn R-CNN vào năm 2015, chỉ 1 năm sau sự ra đời của nó, đó chính là Fast R-CNN. Fast R-CNN là một phiên bản hoàn thiện hơn và khắc phục được các hạn chế mà R-CNN còn mắc phải.","headline":"Fast R-CNN cho nhận diện đối tượng","mainEntityOfPage":{"@type":"WebPage","@id":"https://tailtq.github.io/posts/fast-rcnn-for-object-detection/"},"url":"https://tailtq.github.io/posts/fast-rcnn-for-object-detection/"}</script><title>Fast R-CNN cho nhận diện đối tượng | Tailtq</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Tailtq"><meta name="application-name" content="Tailtq"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script defer src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.15.0,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script async src="https://cdn.jsdelivr.net/combine/npm/lozad/dist/lozad.min.js,npm/magnific-popup@1/dist/jquery.magnific-popup.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script> /* see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> */ MathJax = { tex: { inlineMath: [ /* start/end delimiter pairs for in-line math */ ['$','$'], ['\\(','\\)'] ], displayMath: [ /* start/end delimiter pairs for display math */ ['$$', '$$'], ['\\[', '\\]'] ] } }; </script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript" id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"> </script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=G-ZB7VQFD7XK"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-ZB7VQFD7XK'); }); </script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-right"><div id="avatar"> <a href="/" alt="avatar"> <img src="/assets/img/avatar.jpg" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">Tailtq</a></div><div class="site-subtitle">A software developer who enjoys learning, reading, and building things</div></div><hr><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <span>Home</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <span>About me</span> </a><li class="nav-item"> <a href="/interesting-blogs/" class="nav-link"> <span>Interesting blogs</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <span>Archives</span> </a><li class="nav-item"> <a href="https://github.com/tailtq" class="nav-link" target="_blank"> <span>GitHub</span> </a><li class="nav-item}"> <a href="https://www.linkedin.com/in/tai-le-05124a187/" class="nav-link" target="_blank"> <span>Linkedin</span> </a></ul></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Posts </a> </span> <span>Fast R-CNN cho nhận diện đối tượng</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>Fast R-CNN cho nhận diện đối tượng</h1><div class="post-meta text-muted d-flex flex-column"><div> <span class="semi-bold"> Tai Le </span> <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Mon, Sep 14, 2020, 12:00 AM +0700" prep="on" > Sep 14, 2020 <i class="unloaded">2020-09-14T00:00:00+07:00</i> </span></div><div> <span> <span class="timeago lastmod" data-toggle="tooltip" data-placement="bottom" title="Sun, Aug 7, 2022, 11:49 PM +0700" prefix="Updated " > Aug 7, 2022 <i class="unloaded">2022-08-07T23:49:43+07:00</i> </span> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="1798 words">9 min</span></div></div><div class="post-content"><p>Sau khi đã tìm hiểu về R-CNN, chúng ta hãy cùng đi tìm hiểu về một kiến trúc tối tân hơn R-CNN vào năm 2015, chỉ 1 năm sau sự ra đời của nó, đó chính là Fast R-CNN. Fast R-CNN là một phiên bản hoàn thiện hơn và khắc phục được các hạn chế mà R-CNN còn mắc phải.</p><p>Trong bài viết này, chúng ta sẽ tìm hiểu về điểm đặc biệt của Fast R-CNN so với người đàn anh của nó, cách network này giải quyết các vấn đề của R-CNN, đồng thời khám phá sâu hơn về cách network này được huấn luyện.</p><h1 id="kiến-trúc">Kiến trúc</h1><p>Trong mục này, chúng ta sẽ tập trung vào cách mà Fast R-CNN hoạt động để hiểu được bức tranh toàn cảnh. Sau đó, chúng ta sẽ khai phá sâu hơn về từng component trong network này.</p><p>Fast R-CNN đã bỏ lớp SVM mà R-CNN đã sử dụng để xác định đối tượng sau khi chiết xuất đặc trưng, thay vào đó, network này là một model thống nhất, giải quyết việc phân loại và định vị đối tượng. Bằng hướng tiếp cận này, Fast R-CNN đã loại bỏ được 2 trong 3 khuyết điểm của R-CNN, đó chính là:</p><ul><li>Sự phức tạp khi huấn luyện model<li>Không gian lưu trữ cho các model SVM</ul><p>Thêm vào đó, bằng cách tích hợp <strong>RoI Pooling Layer</strong>, khuyết điểm còn lại là hiệu năng cũng được giảm đi đáng kể. Bạn có thể tham khảo bảng thời gian hiệu năng bên dưới.</p><p style="text-align: center;"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/2020-09-14/fast-rcnn-performance.png" alt="Architecture" /></p><p>Vì đã là một thể thống nhất, chúng ta có thể thoải mái huấn luyện và điều chỉnh các thông số của model, không cần phải quan tâm việc lấy đặc trưng từ CNN và feed vào SVMs nữa.</p><p>Model này cũng sử dụng Softmax thay cho one-vs-rest SVMs, nên dung lượng model sẽ giảm đi đáng kể so với R-CNN. Theo một thử nghiệm trong paper, việc sử dụng Softmax trong Fast R-CNN vượt trội hơn 0.1 đến 0.8 mAP point so với SVM. Vậy là tiện cả đôi đường :D.</p><p>Vì có khả năng giải quyết được nhiều tác vụ trong cùng một model, có thể đoán chắc rằng kiến trúc của Fast R-CNN sẽ phức tạp hơn so với kiến trúc cũ. Để hiểu rõ hơn về kiến trúc, bạn có thể nhìn hình dưới.</p><p style="text-align: center;"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/2020-09-14/architecture.png" alt="Architecture" /></p><p>Giả sử chúng ta cần phát hiện $K$ lớp đối tượng.</p><ol><li>Selective search được sử dụng để lấy các RoIs từ ảnh<li>CNN chiết xuất tất cả đặc trưng của ảnh thành feature map<li>Theo từng RoI, network ánh xạ đến feature map tổng để lấy một feature map trong vùng đó, sau đó cung cấp cho RoI Pooling Layer<li>Kết quả từ RoI Pooling Layer là một feature vector và được cung cấp cho fully connected layer, layer này được chia thành 2 nhánh con để thực hiện 2 nhiệm vụ khác nhau, và kết quả là xác suất cho $K$ lớp đối tượng đồng thời vị trí của mỗi đối tượng đó.</ol><p>Không quá phức tạp nhỉ? Đúng vậy, tuy nhiên để huấn luyện model này, chúng ta cần phải quan tâm đến các thành phần quan trọng như:</p><ul><li>RoI Pooling Layer<li>Loss function<li>Back propagation</ul><p>Ở các mục tiếp theo, chúng ta sẽ làm rõ từng phần này.</p><p>Lưu ý: Để tránh nhầm lẫn, tôi xin được gọi feature map của CNN là <strong>feature map tổng</strong>, còn của RoI thì vẫn giữ nguyên là <strong>feature map</strong>.</p><h1 id="roi-pooling-layer">RoI Pooling Layer</h1><p>Như các bạn đã biết, đầu vào cho FCN phải là các dữ liệu có kích thước cố định, tuy nhiên thì các RoI chắc chắn sẽ có nhiều kích thước khác nhau, như kích thước của 2 chú gấu ở hình dưới.</p><p style="text-align: center;"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/2020-09-14/red-panda.jpg" alt="Architecture" /></p><p>Vì vậy, CNN của chúng ta sẽ gặp rắc rối ở đây, bởi vì thông thường đối với các bài toán phân loại, kích thước hình ảnh sẽ được co giãn thành một giá trị cố định. Do đó, <strong>RoI Pooling Layer</strong> sẽ được sử dụng để biến đổi các kích thước ngẫu nhiên thành cố định. Đầu tiên, chúng ta cần phải hiểu khái niệm <strong>RoI Max Pooling</strong>, các bạn có thể tham khảo hình dưới.</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/2020-09-14/roi-max-pooling.gif" alt="RoI Max Pooling" /></p><p>Giả sử, một feature map tổng có size <code class="language-plaintext highlighter-rouge">8x8</code>, tuy nhiên feature map của RoI chỉ có kích thước <code class="language-plaintext highlighter-rouge">5x7</code>, để lấy một feature map mới từ RoI (kích thước <code class="language-plaintext highlighter-rouge">2x2</code> như trong ảnh), chúng ta cần phải chia kích thước của feature map thành <code class="language-plaintext highlighter-rouge">2x2</code> phần, mỗi phần sẽ có kích thước tương đối bằng nhau, sau đó lấy giá trị tối đa của từng phần.</p><p>Tiếp theo, chúng ta hãy tìm hiểu khái niệm <strong>RoI Pooling Layer</strong>. Dựa trên nghiên cứu của SPPnets, Fast R-CNN sử dụng khái niệm này để diễn tả một trường hợp đặc biệt của <strong>Spatial Pyramid Pooling Layer</strong>. Hình bên dưới sẽ mô tả cách layer này hoạt động.</p><p style="text-align: center;"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/2020-09-14/roi-pooling-layer.png" alt="RoI Pooling Layer" /></p><p>Ở đây, bạn có thể thấy rằng chúng ta đã quy định 3 kích thước: <code class="language-plaintext highlighter-rouge">4x4</code>, <code class="language-plaintext highlighter-rouge">2x2</code> và <code class="language-plaintext highlighter-rouge">1x1</code>, số lượng này sẽ tuỳ các bạn đặt ra bất kể kích thước của feature map. RoI Pooling Layer sẽ áp dụng RoI Max Pooling cho từng kích thước, sau đó sẽ nối kết quả của từng kích thước lại tạo nên một feature vector có kích thước cố định cho mọi RoI, trong trường hợp này là <code class="language-plaintext highlighter-rouge">21x256</code>. Lưu ý rằng 256 ở đây là số lượng filter cho layer này.</p><h1 id="huấn-luyện">Huấn luyện</h1><p>Như đã đề cập ở trên, network đã được gom thành một thể thống nhất, việc huấn luyện sẽ trở nên dễ dàng hơn. Vì vậy, Loss function phải trở nên phức tạp hơn để đánh giá độ chính xác của hai nhiệm vụ, từ nhiệm vụ phân loại cho đến xác định bounding box. Đồng thời Back propagation cũng cần phải được cải tiến để phù hợp với RoI Pooling Layer.</p><p>Trước tiên, để tìm hiểu việc huấn luyện đa nhiệm vụ như thế nào, thì bạn có thể tham khảo <a href="https://github.com/hosseinshn/Basic-Multi-task-Learning/blob/master/MTL-Pytorch.ipynb">link</a> này, được viết bằng PyTorch.</p><p>Khi tìm hiểu về Loss Function và Back propagation, chúng ta cần biết rằng Optimization function của Fast R-CNN là Stochastic Gradient Descent (SGD). Các bạn có thắc mắc rằng nếu nhiều đối tượng trong cùng một ảnh được huấn luyện thì quá trình converge sẽ lâu hơn không? Dựa trên paper, vấn đề này thực tế không xuất hiện, và Fast R-CNN train với ít lần lặp hơn so với R-CNN.</p><p>Bây giờ chúng ta sẽ bắt đầu tìm hiểu Loss function và Back propagation nhé.</p><h2 id="loss-function">Loss function</h2><p>Không như AlexNet sử dụng Cross Entropy loss, Fast R-CNN sử dụng loss function mới trong ngữ cảnh này, đảm bảo rằng loss của kết quả trả về từ nhiệm vụ phân loại và định vị bounding box sẽ là ngang nhau. Dưới đây là công thức của loss function:</p>\[L(p, u, t^u, v) = L_{cls}(p, u) + \lambda[u \geq 1]L_{loc}(t^u, v)\]<p>Ban đầu chúng ta sẽ nhìn tổng quan loss function này, sau đó sẽ đi sâu vào phân tích từng công thức. Hàm này được cấu thành từ loss của 2 nhánh mà FCN đã chia ra, đó là $ L_{cls} $ (phân loại) và $ L_{loc} $ (định vị).</p><h3 id="nhiệm-vụ-phân-loại-classification">Nhiệm vụ phân loại (classification)</h3>\[L_{cls}(p, u) = -\log(p_u)\]<p><u>Ký hiệu:</u></p><ul><li>$p$: xác suất của K lớp<li>$u$: xác suất của ground-truth</ul><p>Theo như công thức, với loss cho nhiệm vụ phân loại, chúng ta chỉ nhận $\log$ của lớp trùng với ground-truth $u$.</p><h3 id="nhiệm-vụ-định-vị-bounding-box">Nhiệm vụ định vị bounding box</h3>\[L_{loc}(t^u, v) = \sum_{i \in \{x, y, w, h\}} smooth_{L_1}(t_i^u - v_i)\]<p>Với:</p>\[smooth_{L_1}(x) = \begin{cases} 0.5x^2 &amp; \text{if $\lvert x \lvert &lt; 1$} \\ \lvert x \lvert - 0.5 &amp; \text{otherwise} \end{cases}\]<p><u>Ký hiệu:</u></p><ul><li>$t_i^u = (t_x^u, t_y^u, t_w^u, t_h^u)$: Bounding box được dự đoán cho ground-truth<li>$v$: Ground-truth bounding box</ul><p>Trước tiên, chúng ta cần phải hiểu rằng nhiệm vụ này là một nhiệm vụ hồi quy (regression). Loss của background bounding box sẽ bị loại bằng $[u \geq 1]$ trong $(1)$, đồng thời loss chỉ dựa trên ground-truth như nhiệm vụ phân loại. Nếu bạn tự hỏi $\lambda$ được sử dụng làm gì, thì bạn khá tinh tế đấy, tham số này là tỉ lệ giữa nhiệm vụ phân loại và nhận diện bounding box, trong paper mặc định $\lambda = 1$.</p><p><u>Lưu ý:</u> Dữ liệu của bounding box cần được scale xuống khoảng $[0, 1]$</p><h2 id="back-propagation">Back propagation</h2><p>Đã hiểu được RoI Pooling Layer rồi, bây giờ chúng ta cũng cần phải hiểu cách gradients từ fully connected layer được truyền qua layer này để cập nhật trọng số của các convolutional layer. Phần này tôi sẽ nói theo cách hiểu của mình dựa trên paper.</p><p>Dưới đây là công thức toán học mô tả cách hoạt động của RoI Max Pooling (hiểu forward trước khi nghiên cứu backward):</p>\[y_{rj} = x_{i^*(r, j)}\]<p>Với</p>\[i^*(r,j) = \underset{i' \in R(r, j)}{\operatorname{argmax}}x_{i'}\]<p><u>Ký hiệu:</u></p><ul><li>$x_i \in \mathbb{R}$: Giá trị đầu vào activation $i$ truyền vào RoI Pooling Layer<li>$y_{rj}$: Kết quả của layer $j$ từ RoI thứ $r$</ul><p>Như đã nói ở trên, đối với mỗi RoI, chúng ta sẽ cần chiết xuất feature vector tương ứng. Dựa theo từng phần, ký hiệu là $ R(r, j) $, của kích thước trong RoI Max Pooling, ta cần tìm vị trí $ i∗(r, j) $ sao cho activation của vị trí này trong vùng $ R(r, j) $ là lớn nhất. Lưu ý rằng tùy theo giá trị của kích thước mà $j$ có thể thay đổi.</p><p>Tiếp theo đến phần backward, khi cập nhật gradient, chúng ta chỉ cần quan tâm đến các vị trí $ i = i∗(r, j) $ trong một RoI, các vị trí khác sẽ không có gradient, công thức ở dưới sẽ thể hiện rõ việc này.</p>\[\frac{\partial L}{\partial x_i} = \sum_{r}\sum_{j}[ i = i∗(r, j)] \frac{\partial L}{\partial y_{rj}}\]<h1 id="khuyết-điểm">Khuyết điểm</h1><p>Như hình ở trên, khi test thì chỉ mất khoảng 2.3s, nếu so với R-CNN thì mất tận 49s. Tuy nhiên, khuyết điểm của Fast R-CNN nằm ở Selective Search, thuật toán này tốn nhiều thời gian để tạo nên các RoI so với tổng thời gian của network. Vì vậy ở Faster R-CNN, các nhà nghiên cứu đã thay Selective Search bằng Region Proposals Network để học các vùng RoI.</p><hr /><h1 id="kết-luận">Kết luận</h1><p>Vậy là chúng ta đã đi xong Fast R-CNN rồi. Trong bài viết sắp tới tôi sẽ nghiên cứu Faster R-CNN, các bạn nhớ theo dõi nhé.</p><h1 id="tài-liệu">Tài liệu</h1><ol><li><p><a href="https://arxiv.org/pdf/1504.08083.pdf">Paper</a></p><li><p><a href="https://stackoverflow.com/questions/43430056/what-is-the-purpose-of-the-roi-layer-in-a-fast-r-cnn">What is the purpose of the ROI layer in a Fast R-CNN?</a></p><li><p><a href="https://deepsense.io/region-of-interest-pooling-explained/">Region of interest pooling explained</a></p><li><p><a href="https://blog.acolyer.org/2017/03/21/convolution-neural-nets-part-2">Convolution neural nets, Part 2</a></p><li><p><a href="https://datascience.stackexchange.com/questions/11699/backprop-through-max-pooling-layers">Back propagation through Max Pooling layer</a></p><li><p><a href="https://github.com/hosseinshn/Basic-Multi-task-Learning/blob/master/MTL-Pytorch.ipynb">Multi-task training with PyTorch</a></p></ol></div><div class="post-tail-wrapper text-muted"><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/ai/" class="post-tag no-text-decoration" >AI</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Fast R-CNN cho nhận diện đối tượng - Tailtq&url=https://tailtq.github.io/posts/fast-rcnn-for-object-detection/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Fast R-CNN cho nhận diện đối tượng - Tailtq&u=https://tailtq.github.io/posts/fast-rcnn-for-object-detection/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=Fast R-CNN cho nhận diện đối tượng - Tailtq&url=https://tailtq.github.io/posts/fast-rcnn-for-object-detection/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i class="fa-fw fas fa-link small" onclick="copyLink()" data-toggle="tooltip" data-placement="top" title="Copy link"></i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"> <span>Recent Update</span><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/asynchronous-programming/">Asynchronous Programming</a><li><a href="/posts/streamlit-a-fast-way-to-build-web-applications/">Streamlit - A Fast Way to Build Web Applications</a><li><a href="/posts/modify-facebook-duckling/">Modify Facebook's Duckling</a><li><a href="/posts/tensorflow-with-amd-ubuntu/">Use Tensorflow with AMD GPU on Ubuntu</a><li><a href="/posts/how-i-reduced-rasa-testing-time-by-60-80/">How I reduced RASA testing time by 60-80%</a></ul></div><div id="access-tags"> <span>Trending Tags</span><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/python/">Python</a> <a class="post-tag" href="/tags/ai/">AI</a> <a class="post-tag" href="/tags/back-end/">Back-end</a> <a class="post-tag" href="/tags/database/">Database</a> <a class="post-tag" href="/tags/devops/">DevOps</a> <a class="post-tag" href="/tags/front-end/">Front-end</a> <a class="post-tag" href="/tags/haskell/">Haskell</a> <a class="post-tag" href="/tags/math/">Math</a> <a class="post-tag" href="/tags/mysql/">MySQL</a> <a class="post-tag" href="/tags/tensorflow/">Tensorflow</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"> <span class="pl-3 pt-2 mb-2">Contents</span><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/how-i-reduced-rasa-testing-time-by-60-80/"><div class="card-body"> <span class="timeago small" > Aug 6, 2022 <i class="unloaded">2022-08-06T00:00:00+07:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>How I reduced RASA testing time by 60-80%</h3><div class="text-muted small"><p> It is quite a long time since I wrote my latest post, and now I come back stronger with a topic that contains both Back-end and AI. It is my journey to customize the Natural Language Understanding ...</p></div></div></a></div><div class="card"> <a href="/posts/tensorflow-with-amd-ubuntu/"><div class="card-body"> <span class="timeago small" > Apr 21, 2020 <i class="unloaded">2020-04-21T00:00:00+07:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Use Tensorflow with AMD GPU on Ubuntu</h3><div class="text-muted small"><p> After I received my graphic card (Radeon RX 570 Series) from my cousin. So I started using Tensorflow and found out my training process was also extremely slow, like when training with my MacOS...</p></div></div></a></div><div class="card"> <a href="/posts/cat-and-dog-recognition-using-keras/"><div class="card-body"> <span class="timeago small" > Apr 26, 2020 <i class="unloaded">2020-04-26T00:00:00+07:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Cat & dog recognition using Keras</h3><div class="text-muted small"><p> For Machine Learning beginners who just know about basic agorithms and want more - get involved in Computer Vision projects, cat &amp; dog recognition is a fairly straightforward problem that e...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/region-based-convolutional-neural-network/" class="btn btn-outline-primary" prompt="Older"><p>R-CNN - Region-based Convolutional Neural Network</p></a> <a href="/posts/mat-cheat-sheet-and-notes/" class="btn btn-outline-primary" prompt="Newer"><p>Math Cheat Sheet & Notes</p></a></div></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2023 <a href="https://twitter.com/username">Tai Le</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/python/">Python</a> <a class="post-tag" href="/tags/ai/">AI</a> <a class="post-tag" href="/tags/back-end/">Back end</a> <a class="post-tag" href="/tags/database/">Database</a> <a class="post-tag" href="/tags/devops/">DevOps</a> <a class="post-tag" href="/tags/front-end/">Front end</a> <a class="post-tag" href="/tags/haskell/">Haskell</a> <a class="post-tag" href="/tags/math/">Math</a> <a class="post-tag" href="/tags/mysql/">MySQL</a> <a class="post-tag" href="/tags/tensorflow/">Tensorflow</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://tailtq.github.io{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script>
