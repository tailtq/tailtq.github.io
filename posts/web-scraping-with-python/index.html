<!DOCTYPE html><html lang="en-US" mode="light" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="generator" content="Jekyll v4.3.2" /><meta property="og:title" content="Web Scraping with Python" /><meta name="author" content="Tai Le" /><meta property="og:locale" content="en_US" /><meta name="description" content="I have just finished the book Web Scraping with Python yesterday, itâ€™s a useful book that helps you improve your scraping skills. There is some useful information there, you should take a look before deciding to work on any scraping projects. Below are the things that are helpful in my future scraping projects." /><meta property="og:description" content="I have just finished the book Web Scraping with Python yesterday, itâ€™s a useful book that helps you improve your scraping skills. There is some useful information there, you should take a look before deciding to work on any scraping projects. Below are the things that are helpful in my future scraping projects." /><link rel="canonical" href="https://tailtq.github.io/posts/web-scraping-with-python/" /><meta property="og:url" content="https://tailtq.github.io/posts/web-scraping-with-python/" /><meta property="og:site_name" content="Tailtq" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2022-06-17T00:00:00+07:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Web Scraping with Python" /><meta name="twitter:site" content="@twitter_username" /><meta name="twitter:creator" content="@Tai Le" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Tai Le"},"dateModified":"2022-06-17T00:00:00+07:00","datePublished":"2022-06-17T00:00:00+07:00","description":"I have just finished the book Web Scraping with Python yesterday, itâ€™s a useful book that helps you improve your scraping skills. There is some useful information there, you should take a look before deciding to work on any scraping projects. Below are the things that are helpful in my future scraping projects.","headline":"Web Scraping with Python","mainEntityOfPage":{"@type":"WebPage","@id":"https://tailtq.github.io/posts/web-scraping-with-python/"},"url":"https://tailtq.github.io/posts/web-scraping-with-python/"}</script><title>Web Scraping with Python | Tailtq</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="Tailtq"><meta name="application-name" content="Tailtq"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="https://cdn.jsdelivr.net"><link rel="dns-prefetch" href="https://cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script defer src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.15.0,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script async src="https://cdn.jsdelivr.net/combine/npm/lozad/dist/lozad.min.js,npm/magnific-popup@1/dist/jquery.magnific-popup.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=G-ZB7VQFD7XK"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'G-ZB7VQFD7XK'); }); </script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-right"><div id="avatar"> <a href="/" alt="avatar"> <img src="/assets/img/avatar.jpg" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">Tailtq</a></div><div class="site-subtitle">A software developer who enjoys learning, reading, and building things</div></div><hr><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <span>Home</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <span>About me</span> </a><li class="nav-item"> <a href="/interesting-blogs/" class="nav-link"> <span>Interesting blogs</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <span>Archives</span> </a><li class="nav-item"> <a href="https://github.com/tailtq" class="nav-link" target="_blank"> <span>GitHub</span> </a><li class="nav-item}"> <a href="https://www.linkedin.com/in/tai-le-05124a187/" class="nav-link" target="_blank"> <span>Linkedin</span> </a></ul></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/"> Posts </a> </span> <span>Web Scraping with Python</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>Web Scraping with Python</h1><div class="post-meta text-muted d-flex flex-column"><div> <span class="semi-bold"> Tai Le </span> <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Fri, Jun 17, 2022, 12:00 AM +0700" prep="on" > Jun 17, 2022 <i class="unloaded">2022-06-17T00:00:00+07:00</i> </span></div><div> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="1130 words">6 min</span></div></div><div class="post-content"><p>I have just finished the book <strong>Web Scraping with Python</strong> yesterday, itâ€™s a useful book that helps you improve your scraping skills. There is some useful information there, you should take a look before deciding to work on any scraping projects. Below are the things that are helpful in my future scraping projects.</p><h2 id="1-try-except-is-a-savior">1. Try-except is a savior</h2><p>Imagine you are crawling a big site with 100.000 data items, it takes you a few days to complete. If any exception happens (resource not found, the server is down), it will disrupt the whole process and you have to run over again.</p><p>Therefore, in my opinion, try-except and exception handlers are extremely important during any long scraping process.</p><h2 id="2-dealing-with-placeholder-images">2. Dealing with placeholder images</h2><p>Most websites rendering images often use the blank images or base64 content as a placeholder to prevent layout reflow, where the content below or around the image gets pushed to make room for the freshly loaded image. Therefore, we have to ignore them completely and aim for the original links.</p><p>Thankfully, the book uses <code class="language-plaintext highlighter-rouge">BeautifulSoup</code>, it is a strong library that is based on top of the parsers (HTML, XML, â€¦) to extract the content. The library below supports Regex to selectively choose the appropriate content. We can write some patterns to skip the base64 content and the blank images.</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
</pre><td class="rouge-code"><pre><span class="c1"># the code here is retrieved from Web Scraping with Python
</span><span class="kn">import</span> <span class="n">re</span>
<span class="kn">import</span> <span class="n">requests</span>
<span class="kn">from</span> <span class="n">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>

<span class="n">res</span> <span class="o">=</span> <span class="n">requests</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="s">'http://www.pythonscraping.com/pages/page3.html'</span><span class="p">)</span>
<span class="n">html</span> <span class="o">=</span> <span class="n">res</span><span class="p">.</span><span class="n">content</span><span class="p">.</span><span class="nf">decode</span><span class="p">(</span><span class="s">'utf-8'</span><span class="p">)</span>
<span class="n">bs</span> <span class="o">=</span> <span class="nc">BeautifulSoup</span><span class="p">(</span><span class="n">html</span><span class="p">,</span> <span class="s">'html.parser'</span><span class="p">)</span>
<span class="c1"># ignore placeholder images
</span><span class="n">images</span> <span class="o">=</span> <span class="n">bs</span><span class="p">.</span><span class="nf">find_all</span><span class="p">(</span><span class="s">'img'</span><span class="p">,</span> <span class="p">{</span><span class="s">'src'</span><span class="p">:</span><span class="n">re</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="s">'\.\.\/img\/gifts/img.*\.jpg'</span><span class="p">)})</span>
<span class="k">for</span> <span class="n">image</span> <span class="ow">in</span> <span class="n">images</span><span class="p">:</span>
    <span class="nf">print</span><span class="p">(</span><span class="n">image</span><span class="p">[</span><span class="s">'src'</span><span class="p">])</span>
</pre></table></code></div></div><h2 id="3-crawl-an-entire-website">3. Crawl an entire website</h2><p>In the past, I wondered how to write a scraper to crawl the entire website. Fortunately, I have found the secret ingredient here, the whole process only contains 3 steps:</p><ol><li>Crawl any pages any page on the website<li>Parse and get all internal links<li>Recursively do the first and second steps</ol><p><strong>Note:</strong> We need to maintain a links list that was already crawled to avoid infinite recursion.</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
</pre><td class="rouge-code"><pre><span class="c1"># the code here is retrieved from Web Scraping with Python
</span><span class="kn">from</span> <span class="n">urllib.request</span> <span class="kn">import</span> <span class="n">urlopen</span>
<span class="kn">from</span> <span class="n">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>
<span class="kn">import</span> <span class="n">re</span>

<span class="n">pages</span> <span class="o">=</span> <span class="nf">set</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">getLinks</span><span class="p">(</span><span class="n">pageUrl</span><span class="p">):</span>
    <span class="k">global</span> <span class="n">pages</span>
    <span class="n">html</span> <span class="o">=</span> <span class="nf">urlopen</span><span class="p">(</span><span class="s">'http://en.wikipedia.org{}'</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">pageUrl</span><span class="p">))</span>
    <span class="n">bs</span> <span class="o">=</span> <span class="nc">BeautifulSoup</span><span class="p">(</span><span class="n">html</span><span class="p">,</span> <span class="s">'html.parser'</span><span class="p">)</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="nf">print</span><span class="p">(</span><span class="n">bs</span><span class="p">.</span><span class="n">h1</span><span class="p">.</span><span class="nf">get_text</span><span class="p">())</span>
        <span class="nf">print</span><span class="p">(</span><span class="n">bs</span><span class="p">.</span><span class="nf">find</span><span class="p">(</span><span class="nb">id</span> <span class="o">=</span><span class="s">'mw-content-text'</span><span class="p">).</span><span class="nf">find_all</span><span class="p">(</span><span class="s">'p'</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>
        <span class="nf">print</span><span class="p">(</span><span class="n">bs</span><span class="p">.</span><span class="nf">find</span><span class="p">(</span><span class="nb">id</span><span class="o">=</span><span class="s">'ca-edit'</span><span class="p">).</span><span class="nf">find</span><span class="p">(</span><span class="s">'span'</span><span class="p">).</span><span class="nf">find</span><span class="p">(</span><span class="s">'a'</span><span class="p">).</span><span class="n">attrs</span><span class="p">[</span><span class="s">'href'</span><span class="p">])</span>
    <span class="k">except</span> <span class="nb">AttributeError</span><span class="p">:</span>
        <span class="nf">print</span><span class="p">(</span><span class="s">'This page is missing something! Continuing.'</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">link</span> <span class="ow">in</span> <span class="n">bs</span><span class="p">.</span><span class="nf">find_all</span><span class="p">(</span><span class="s">'a'</span><span class="p">,</span> <span class="n">href</span><span class="o">=</span><span class="n">re</span><span class="p">.</span><span class="nf">compile</span><span class="p">(</span><span class="s">'^(/wiki/)'</span><span class="p">)):</span>
        <span class="k">if</span> <span class="s">'href'</span> <span class="ow">in</span> <span class="n">link</span><span class="p">.</span><span class="n">attrs</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">link</span><span class="p">.</span><span class="n">attrs</span><span class="p">[</span><span class="s">'href'</span><span class="p">]</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">pages</span><span class="p">:</span>
                <span class="c1">#We have encountered a new page
</span>                <span class="n">newPage</span> <span class="o">=</span> <span class="n">link</span><span class="p">.</span><span class="n">attrs</span><span class="p">[</span><span class="s">'href'</span><span class="p">]</span>
                <span class="nf">print</span><span class="p">(</span><span class="s">'-'</span><span class="o">*</span><span class="mi">20</span><span class="p">)</span>
                <span class="nf">print</span><span class="p">(</span><span class="n">newPage</span><span class="p">)</span>
                <span class="n">pages</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="n">newPage</span><span class="p">)</span>
                <span class="nf">getLinks</span><span class="p">(</span><span class="n">newPage</span><span class="p">)</span>
<span class="nf">getLinks</span><span class="p">(</span><span class="s">''</span><span class="p">)</span>
</pre></table></code></div></div><h2 id="4-dealing-with-different-website-layouts">4. Dealing with Different Website Layouts</h2><p>When crawling specific content (such as blog articles, news, and mangas) from multiple websites, itâ€™s important to have a consistent class blueprint whose each property describes the DOM path of an element in the content. With the same code, we can crawl thousands of websitesâ€™ layouts with little effort.</p><p>For example, the code below crawls the title and content of 4 articles on 4 different websites. If it was me in the past, I would create 4 different functions to handle the tasks.</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
</pre><td class="rouge-code"><pre><span class="c1"># the code here is retrieved from Web Scraping with Python
</span><span class="kn">import</span> <span class="n">requests</span>
<span class="kn">from</span> <span class="n">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>

<span class="k">class</span> <span class="nc">Crawler</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">getPage</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">URL</span><span class="p">):</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">req</span> <span class="o">=</span> <span class="n">requests</span><span class="p">.</span><span class="nf">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
        <span class="k">except</span> <span class="n">requests</span><span class="p">.</span><span class="n">exceptions</span><span class="p">.</span><span class="n">RequestException</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">None</span>
        <span class="k">return</span> <span class="nc">BeautifulSoup</span><span class="p">(</span><span class="n">req</span><span class="p">.</span><span class="n">text</span><span class="p">,</span> <span class="s">'html.parser'</span><span class="p">)</span>

        <span class="k">def</span> <span class="nf">safeGet</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">pageObj</span><span class="p">,</span> <span class="n">selector</span><span class="p">):</span>
            <span class="s">"""
            Utility function used to get a content string from a
            Beautiful Soup object and a selector. Returns an empty
            string if no object is found for the given selector
            """</span>
            <span class="n">selectedElems</span> <span class="o">=</span> <span class="n">pageObj</span><span class="p">.</span><span class="nf">select</span><span class="p">(</span><span class="n">selector</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">selectedElems</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span> <span class="ow">and</span> <span class="nf">len</span><span class="p">(</span><span class="n">selectedElems</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">return</span> <span class="s">'</span><span class="se">\n</span><span class="s">'</span><span class="p">.</span><span class="nf">join</span><span class="p">([</span><span class="n">elem</span><span class="p">.</span><span class="nf">get_text</span><span class="p">()</span> <span class="k">for</span> <span class="n">elem</span> <span class="ow">in</span> <span class="n">selectedElems</span><span class="p">])</span>
            <span class="k">return</span> <span class="s">''</span>

        <span class="k">def</span> <span class="nf">parse</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">site</span><span class="p">,</span> <span class="n">url</span><span class="p">):</span>
            <span class="s">"""
            Extract content from a given page URL
            """</span>
            <span class="n">bs</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">getPage</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">bs</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
                <span class="n">title</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">safeGet</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="n">site</span><span class="p">.</span><span class="n">titleTag</span><span class="p">)</span>
                <span class="n">body</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">safeGet</span><span class="p">(</span><span class="n">bs</span><span class="p">,</span> <span class="n">site</span><span class="p">.</span><span class="n">bodyTag</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">title</span> <span class="o">!=</span> <span class="s">''</span> <span class="ow">and</span> <span class="n">body</span> <span class="o">!=</span> <span class="s">''</span><span class="p">:</span>
                    <span class="n">content</span> <span class="o">=</span> <span class="nc">Content</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">title</span><span class="p">,</span> <span class="n">body</span><span class="p">)</span>
                    <span class="n">content</span><span class="p">.</span><span class="nf">print</span><span class="p">()</span>

<span class="k">class</span> <span class="nc">Content</span><span class="p">:</span>
    <span class="s">"""
    Common base class for all articles/pages
    """</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">url</span><span class="p">,</span> <span class="n">title</span><span class="p">,</span> <span class="n">body</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">url</span> <span class="o">=</span> <span class="n">url</span>
        <span class="n">self</span><span class="p">.</span><span class="n">title</span> <span class="o">=</span> <span class="n">title</span>
        <span class="n">self</span><span class="p">.</span><span class="n">body</span> <span class="o">=</span> <span class="n">body</span>
    
    <span class="k">def</span> <span class="nf">print</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="s">"""
        Flexible printing function controls the output
        """</span>
        <span class="nf">print</span><span class="p">(</span><span class="s">"URL: {}"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">url</span><span class="p">))</span>
        <span class="nf">print</span><span class="p">(</span><span class="s">"TITLE: {}"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">title</span><span class="p">))</span>
        <span class="nf">print</span><span class="p">(</span><span class="s">"BODY:</span><span class="se">\n</span><span class="s">{}"</span><span class="p">.</span><span class="nf">format</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">body</span><span class="p">))</span>

<span class="k">class</span> <span class="nc">Website</span><span class="p">:</span>
    <span class="s">"""
    Contains information about website structure
    """</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">url</span><span class="p">,</span> <span class="n">titleTag</span><span class="p">,</span> <span class="n">bodyTag</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span>
        <span class="n">self</span><span class="p">.</span><span class="n">url</span> <span class="o">=</span> <span class="n">url</span>
        <span class="n">self</span><span class="p">.</span><span class="n">titleTag</span> <span class="o">=</span> <span class="n">titleTag</span>
        <span class="n">self</span><span class="p">.</span><span class="n">bodyTag</span> <span class="o">=</span> <span class="n">bodyTag</span>

<span class="n">crawler</span> <span class="o">=</span> <span class="nc">Crawler</span><span class="p">()</span>
<span class="n">siteData</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">[</span><span class="s">'O</span><span class="se">\'</span><span class="s">Reilly Media'</span><span class="p">,</span> <span class="s">'http://oreilly.com'</span><span class="p">,</span> <span class="s">'h1'</span><span class="p">,</span> <span class="s">'section#product-description'</span><span class="p">],</span>
    <span class="p">[</span><span class="s">'Reuters'</span><span class="p">,</span> <span class="s">'http://reuters.com'</span><span class="p">,</span> <span class="s">'h1'</span><span class="p">,</span> <span class="s">'div.StandardArticleBody_body_1gnLA'</span><span class="p">],</span>
    <span class="p">[</span><span class="s">'Brookings'</span><span class="p">,</span> <span class="s">'http://www.brookings.edu'</span><span class="p">,</span> <span class="s">'h1'</span><span class="p">,</span> <span class="s">'div.post-body'</span><span class="p">],</span>
    <span class="p">[</span><span class="s">'New York Times'</span><span class="p">,</span> <span class="s">'http://nytimes.com'</span><span class="p">,</span> <span class="s">'h1'</span><span class="p">,</span> <span class="s">'p.story-content'</span><span class="p">]</span>
<span class="p">]</span>
<span class="n">websites</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">siteData</span><span class="p">:</span>
    <span class="n">websites</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="nc">Website</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">row</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">row</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">row</span><span class="p">[</span><span class="mi">3</span><span class="p">]))</span>

<span class="n">crawler</span><span class="p">.</span><span class="nf">parse</span><span class="p">(</span><span class="n">websites</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="s">'http://shop.oreilly.com/product/0636920028154.do'</span><span class="p">)</span>
<span class="n">crawler</span><span class="p">.</span><span class="nf">parse</span><span class="p">(</span><span class="n">websites</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="s">'http://www.reuters.com/article/us-usa-epa-pruitt-idUSKBN19W2D0'</span><span class="p">)</span>
<span class="n">crawler</span><span class="p">.</span><span class="nf">parse</span><span class="p">(</span><span class="n">websites</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="s">'https://www.brookings.edu/blog/techtank/2016/03/01/idea-to-retire-old-methods-of-policy-education/'</span><span class="p">)</span>
<span class="n">crawler</span><span class="p">.</span><span class="nf">parse</span><span class="p">(</span><span class="n">websites</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="s">'https://www.nytimes.com/2018/01/28/business/energy-environment/oil-boom.html'</span><span class="p">)</span>
</pre></table></code></div></div><p>From the code above, <code class="language-plaintext highlighter-rouge">siteData</code> can be retrieved from a database or even a CSV file.</p><h2 id="5-text-encoding">5. Text Encoding</h2><p>Three main encoding formats:</p><ul><li><strong>ASCII</strong><li><strong>UTF-8, UTF-16, UTF-32</strong><li><strong>ISO-8859</strong></ul><p>According to the author, there are 9% of websites use ISO encoding. We can use this tag <code class="language-plaintext highlighter-rouge">&lt;meta charset="utf-8" /&gt;</code> to determine the encoding, hence using the appropriate decoding method.</p><p>You should also note that when reading any kind of content, taking up hard drive space with files when you could easily keep them in memory is bad practice.</p><h2 id="6-submit-form">6. Submit Form</h2><p>Submit form is simple as calling API, but how to break through the CSRF wall is still a mystery to me. ðŸ˜­</p><div class="language-python highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre><span class="kn">import</span> <span class="n">requests</span>

<span class="n">params</span> <span class="o">=</span> <span class="p">{</span><span class="s">'email_addr'</span><span class="p">:</span> <span class="s">'myemail@gmail.com'</span><span class="p">}</span>
<span class="n">r</span> <span class="o">=</span> <span class="n">requests</span><span class="p">.</span><span class="nf">post</span><span class="p">(</span><span class="s">"[http://post.oreilly.com/client/o/oreilly/forms/quicksignup.cgi](http://post.oreilly.com/client/o/oreilly/forms/quicksignup.cgi)"</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">params</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="n">r</span><span class="p">.</span><span class="n">text</span><span class="p">)</span>
</pre></table></code></div></div><h2 id="7-looking-like-a-human">7. Looking Like a Human</h2><p>When we crawl, remember to make your requestsâ€™ headers like the browsers, we can override them with the <code class="language-plaintext highlighter-rouge">requests</code> package in Python. This makes our requests more natural and itâ€™s harder to differentiate between humans and crawlers.</p><p><strong>Major browsersâ€™ header:</strong></p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/2022-06-17/browser-header.png" alt="Untitled" /></p><p><strong>Default urllib libraryâ€™s header:</strong></p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/2022-06-17/urllib-header.png" alt="Untitled" /></p><p>Besides, we should <strong>avoid modifying hidden input fields as well as honeypots</strong>, they are the common security features to double-check the crawlers. On top of that, <strong>timing</strong> is also a critical thing because a single user cannot send hundreds of requests a second.</p><h2 id="8-summary">8. Summary</h2><p>Even though there are more things that should be discussed like Scrapy and Puppeteer, I think they would deserve their own posts due to the immense complexity. That is all for now, thanks for reading.</p><h2 id="9-references">9. References</h2><ul><li>Mitchell. R. (2018). <em>Web Scraping with Python (2nd Edition)</em>. Oâ€™Reilly</ul></div><div class="post-tail-wrapper text-muted"><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/python/" class="post-tag no-text-decoration" >Python</a> <a href="/tags/web-scraping/" class="post-tag no-text-decoration" >Web Scraping</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a> by the author.</div><div class="share-wrapper"> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Web Scraping with Python - Tailtq&url=https://tailtq.github.io/posts/web-scraping-with-python/" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Web Scraping with Python - Tailtq&u=https://tailtq.github.io/posts/web-scraping-with-python/" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=Web Scraping with Python - Tailtq&url=https://tailtq.github.io/posts/web-scraping-with-python/" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <i class="fa-fw fas fa-link small" onclick="copyLink()" data-toggle="tooltip" data-placement="top" title="Copy link"></i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"> <span>Recent Update</span><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/posts/asynchronous-programming/">Asynchronous Programming</a><li><a href="/posts/streamlit-a-fast-way-to-build-web-applications/">Streamlit - A Fast Way to Build Web Applications</a><li><a href="/posts/modify-facebook-duckling/">Modify Facebook's Duckling</a><li><a href="/posts/tensorflow-with-amd-ubuntu/">Use Tensorflow with AMD GPU on Ubuntu</a><li><a href="/posts/how-i-reduced-rasa-testing-time-by-60-80/">How I reduced RASA testing time by 60-80%</a></ul></div><div id="access-tags"> <span>Trending Tags</span><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/python/">Python</a> <a class="post-tag" href="/tags/ai/">AI</a> <a class="post-tag" href="/tags/back-end/">Back-end</a> <a class="post-tag" href="/tags/database/">Database</a> <a class="post-tag" href="/tags/devops/">DevOps</a> <a class="post-tag" href="/tags/front-end/">Front-end</a> <a class="post-tag" href="/tags/haskell/">Haskell</a> <a class="post-tag" href="/tags/math/">Math</a> <a class="post-tag" href="/tags/mysql/">MySQL</a> <a class="post-tag" href="/tags/tensorflow/">Tensorflow</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"> <span class="pl-3 pt-2 mb-2">Contents</span><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/posts/streamlit-a-fast-way-to-build-web-applications/"><div class="card-body"> <span class="timeago small" > Feb 18, 2022 <i class="unloaded">2022-02-18T00:00:00+07:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Streamlit - A Fast Way to Build Web Applications</h3><div class="text-muted small"><p> After I switched to the NLP team in my company, I have had many opportunities to research new technologies, both in Web and AI. My leader introduced Streamlit as a Front-end development library, co...</p></div></div></a></div><div class="card"> <a href="/posts/multithreading-vs-multiprocessing/"><div class="card-body"> <span class="timeago small" > Apr 2, 2022 <i class="unloaded">2022-04-02T00:00:00+07:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Multi-threading vs Multi-processing</h3><div class="text-muted small"><p> At some points, we encounter some problems that make our applications tremendously slow. It could be the amount of computation is large, or accessing multiple resources at the time, or too many tas...</p></div></div></a></div><div class="card"> <a href="/posts/caching/"><div class="card-body"> <span class="timeago small" > May 1, 2022 <i class="unloaded">2022-05-01T00:00:00+07:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Caching</h3><div class="text-muted small"><p> With an anxious feeling at this moment, I have decided to write a blog article to relieve that feeling. Again, it is all about summarizing things that I have recently worked on, this time is some c...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/posts/caching/" class="btn btn-outline-primary" prompt="Older"><p>Caching</p></a> <a href="/posts/how-i-reduced-rasa-testing-time-by-60-80/" class="btn btn-outline-primary" prompt="Newer"><p>How I reduced RASA testing time by 60-80%</p></a></div></div></div></div><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> Â© 2023 <a href="https://twitter.com/username">Tai Le</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/python/">Python</a> <a class="post-tag" href="/tags/ai/">AI</a> <a class="post-tag" href="/tags/back-end/">Back end</a> <a class="post-tag" href="/tags/database/">Database</a> <a class="post-tag" href="/tags/devops/">DevOps</a> <a class="post-tag" href="/tags/front-end/">Front end</a> <a class="post-tag" href="/tags/haskell/">Haskell</a> <a class="post-tag" href="/tags/math/">Math</a> <a class="post-tag" href="/tags/mysql/">MySQL</a> <a class="post-tag" href="/tags/tensorflow/">Tensorflow</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://tailtq.github.io{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script>
